<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · NMOpt</title><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>NMOpt</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/matthewozon/NMOpt/blob/master/docs/src/index.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="NMOpt.jl"><a class="docs-heading-anchor" href="#NMOpt.jl">NMOpt.jl</a><a id="NMOpt.jl-1"></a><a class="docs-heading-anchor-permalink" href="#NMOpt.jl" title="Permalink"></a></h1><p>Documentation for NMOpt.jl</p><article class="docstring"><header><a class="docstring-binding" id="NMOpt.NMOpt" href="#NMOpt.NMOpt"><code>NMOpt.NMOpt</code></a> — <span class="docstring-category">Module</span></header><section><div><p>This is the <a href="#NMOpt.NMOpt"><code>NMOpt</code></a>, it contains </p><ul><li><a href="#NMOpt.BFGS"><code>NMOpt.BFGS</code></a></li><li><a href="#NMOpt.BFGSB"><code>NMOpt.BFGSB</code></a></li><li><a href="#NMOpt.LBFGS"><code>NMOpt.LBFGS</code></a></li><li><a href="#NMOpt.LBFGSB"><code>NMOpt.LBFGSB</code></a></li><li><a href="#NMOpt.belong_to"><code>NMOpt.belong_to</code></a></li><li><a href="#NMOpt.line_search"><code>NMOpt.line_search</code></a></li></ul><p>ref:</p><ul><li>More and Sorensen 1982 (Newton&#39;s method technical report): BFGS</li><li>More 1994 (Line Search Algorithms Sufficient Decrease): line search</li><li>Nocedal 1980 (Updating Quasi-Newton Matrices With Limited Storage): limited memory BFGS</li><li>Thiébaut (Optimization issues in blind deconvolution algorithms): bounded limited memory BFGS, a.k.a vmlmb</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/NMOpt.jl#L19-L33">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NMOpt.BFGS" href="#NMOpt.BFGS"><code>NMOpt.BFGS</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">BFGS(X0::Array{Cdouble,1},H0::Array{Cdouble,2},Nbfgs::Int64,alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,F::Function,Fgrad::Function,Nsearch::Int64=50,tol::Cdouble=1.0e-8;verbose::Bool=false,path::Bool=true)
BFGS(X0::Cdouble,H0::Cdouble,Nbfgs::Int64,alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,F::Function,Fgrad::Function,Nsearch::Int64=50,tol::Cdouble=1.0e-8;verbose::Bool=false,path::Bool=true)

compute ̂x̂ ∈ argmin{F(x)}  using the quasi-Newton method BFGS (see [BFGS wikipedia](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm))

X0:                  starting point
H0:                  initial inverse Hessian matrix
Nbfgs:               maximum number of iterations
alpha_min,alpha_max: line search maximum range
mu:                  line search parameter
Nsearch:             maximum number of iteration for the line search
F:                   cost function to minimize (x::Array{Cdouble}-&gt;F(x))
Fgrad:               gradient of the cost function (x::Array{Cdouble}-&gt;Fgrad(x))
tol:                 relative tolerance (stopping criteria: norm of the gradient difference (y), norm of the step (s) and cos(y,s))

optional arguments:

  - verbose:             verbose if set to true
  - path:                keep track of all iterations if set to true (if false: Xpath=nothing)

output:

  - X:     final state of the optimization process (in the vincinity of argmin{F(x)})
  - H:     estimate of the inverse Hessian matrix 
  - Xpath: steps between the initial point X0 and the arrival point X, or nothing 
  - Nlast: number of iteration</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/BFGS.jl#L9-L38">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NMOpt.BFGSB" href="#NMOpt.BFGSB"><code>NMOpt.BFGSB</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">BFGSB(X0::Array{Cdouble,1},H0::Array{Cdouble,2},Nbfgs::Int64,alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,lx::Union{Cdouble,Array{Cdouble,1}},ux::Union{Cdouble,Array{Cdouble,1}},F::Function,Fgrad::Function,Nsearch::Int64=50,tol::Cdouble=1.0e-8;verbose::Bool=false,path::Bool=true)
BFGSB(X0::Array{Cdouble,1},H0::Array{Cdouble,2},Nbfgs::Int64,alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,lx::Array{Cdouble,1},ux::Array{Cdouble,1},F::Function,Fgrad::Function,Nsearch::Int64=50,tol::Cdouble=1.0e-8;verbose::Bool=false)

compute ̂x̂ ∈ argmin{F(x) | x.&gt;= lx and x.&lt;=ux}  using the quasi-Newton method BFGS (see [BFGS wikipedia](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm))

X0:                  starting point
H0:                  initial inverse Hessian matrix
Nbfgs:               maximum number of iterations
alpha_min,alpha_max: line search maximum range
mu:                  line search parameter
Nsearch:             maximum number of iteration for the line search
F:                   cost function to minimize (x::Array{Cdouble}-&gt;F(x))
Fgrad:               gradient of the cost function (x::Array{Cdouble}-&gt;Fgrad(x))
lx,ux:               lower and upper boundary of ̂x 
tol:                 relative tolerance (stopping criteria: norm of the gradient difference (y), norm of the step (s) and cos(y,s))

optional arguments:

  - verbose:             verbose if set to true
  - path:                keep track of all iterations if set to true (if false: Xpath=nothing)

output:

  - X:     final state of the optimization process (in the vincinity of argmin{F(x)})
  - H:     estimate of the inverse Hessian matrix 
  - Xpath: steps between the initial point X0 and the arrival point X, or nothing 
  - Nlast: number of iteration</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/BFGSB.jl#L9-L39">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NMOpt.LBFGS" href="#NMOpt.LBFGS"><code>NMOpt.LBFGS</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LBFGS(X0::Array{Cdouble,1},H0::Array{Cdouble,2},Nbfgs::Int64,alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,M::Int64,F::Function,Fgrad::Function,Nsearch::Int64=50,tol::Cdouble=1.0e-8;verbose::Bool=false,path::Bool=true)

compute ̂x̂ ∈ argmin{F(x)}  using the limitted memory quasi-Newton method L-BFGS  (see [BFGS wikipedia](https://en.wikipedia.org/wiki/Limited-memory_BFGS))

X0:                  starting point
H0:                  initial inverse Hessian matrix
Nbfgs:               maximum number of iterations
alpha_min,alpha_max: line search maximum range
mu:                  line search parameter
M:                   number of stored vectors (limit memory usage compared with the computation of the inverse of the Hessian matrix)
Nsearch:             maximum number of iteration for the line search
F:                   cost function to minimize (x::Array{Cdouble}-&gt;F(x))
Fgrad:               gradient of the cost function (x::Array{Cdouble}-&gt;Fgrad(x))
tol:                 relative tolerance (stopping criteria: norm of the gradient difference (y), norm of the step (s) and cos(y,s))

optional arguments:

  - verbose: by default set to false 
  - path:    default true, keep track of all the steps between the initial point X0 and the arrival point X (if false: Xpath=nothing)

output:

  - X:     final state of the optimization process (in the vincinity of argmin{F(x)})
  - Xpath: steps between the initial point X0 and the arrival point X
  - Nlast: number of iteration</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/LBFGS.jl#L10-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NMOpt.LBFGSB" href="#NMOpt.LBFGSB"><code>NMOpt.LBFGSB</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LBFGSB(X0::Array{Cdouble,1},H0::Array{Cdouble,2},Nbfgs::Int64,alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,M::Int64,lx::Array{Cdouble,1},ux::Array{Cdouble,1},F::Function,Fgrad::Function,Nsearch::Int64=50,tol::Cdouble=1.0e-8;verbose::Bool=false,path::Bool=true)

compute ̂x̂ ∈ argmin{F(x) | x.&gt;= lx and x.&lt;=ux}  using the limitted memory quasi-Newton method L-BFGS  (see [BFGS wikipedia](https://en.wikipedia.org/wiki/Limited-memory_BFGS))

X0:                  starting point
H0:                  initial inverse Hessian matrix
Nbfgs:               maximum number of iterations
alpha_min,alpha_max: line search maximum range
mu:                  line search parameter
M:                   number of stored vectors (limit memory usage compared with the computation of the inverse of the Hessian matrix)
Nsearch:             maximum number of iteration for the line search
F:                   cost function to minimize (x::Array{Cdouble}-&gt;F(x))
Fgrad:               gradient of the cost function (x::Array{Cdouble}-&gt;Fgrad(x))
lx,ux:               lower and upper boundary of ̂x 
tol:                 relative tolerance (stopping criteria: norm of the gradient difference (y), norm of the step (s) and cos(y,s))

optional arguments:

  - verbose: by default set to false 
  - path:    default true, keep track of all the steps between the initial point X0 and the arrival point X (if false: Xpath=nothing)

output:

  - X:     final state of the optimization process (in the vincinity of argmin{F(x)})
  - Xpath: steps between the initial point X0 and the arrival point X
  - Nlast: number of iteration</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/LBFGSB.jl#L9-L37">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NMOpt.line_search" href="#NMOpt.line_search"><code>NMOpt.line_search</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">line_search(x_::Array{Cdouble,1},p_::Array{Cdouble,1},alpha_min::Cdouble,alpha_max::Cdouble,mu::Cdouble,F::Function,Fgrad::Function,Nsearch::Int64=50;verbose::Bool=false)

compute ̂̂α ∈ argmin{F(x+α*p)}

inputs:

  - x: point x
  - p: search direction 
  - α_min, and α_max:  minimum and maximum values for α
  - μ: weight for the criterion F(x+α*p)&lt;F(x)+μ*α ⟨p,∂F/∂x(x)⟩, and  |⟨p,∂F/∂x(x+α*p)⟩|⩽μ|⟨p,∂F/∂x(x)⟩|
  - F and Fgrad: cost function and its gradient 
  - Nsearch: maximum number of iteration for the line search 

optional argument:

  - verbose: verbose if true 

output: 

  - α within the vincinity of the ̂α</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/lineSearch.jl#L93-L115">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NMOpt.belong_to" href="#NMOpt.belong_to"><code>NMOpt.belong_to</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">belong_to(x_::Array{Cdouble,1},p_::Array{Cdouble,1},alpha_::Cdouble,mu_::Cdouble,F::Function,Fgrad::Function)
belong_to(x_::Cdouble,p_::Cdouble,alpha_::Cdouble,mu_::Cdouble,F::Function,Fgrad::Function)

check the criterion 

F(x+α*p)&lt;F(x)+μ*α ⟨p,∂F/∂x(x)⟩

|⟨p,∂F/∂x(x+α*p)⟩|⩽μ|⟨p,∂F/∂x(x)⟩|

return true if both criterion are met, false otherwise</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/matthewozon/NMOpt/blob/e8a79e0504a6722162d1182259fe00036c613beb/src/lineSearch.jl#L59-L71">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Thursday 24 August 2023 14:01">Thursday 24 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
